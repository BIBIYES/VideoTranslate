# coding: utf-8
"""
Streamlitç•Œé¢ï¼šæä¾›â€œè§†é¢‘è½¬å­—å¹•â€â€œå­—å¹•çƒ§å½•â€â€œAI å­—å¹•ç¿»è¯‘â€ä¸‰ä¸ªå·¥å…·ã€‚

è¿è¡Œ:
    streamlit run streamlit_app.py
"""
import json
from pathlib import Path
import re
import tempfile
from typing import Callable, Dict, List, Sequence

from openai import OpenAI

import streamlit as st

from mian import (
    build_srt_content,
    burn_subtitles,
    extract_audio,
    transcribe_audio,
)


VIDEO_TYPES = ["mp4", "mov", "mkv", "avi"]
AUDIO_TYPES = ["mp3", "wav", "m4a"]

SRT_BLOCK_RE = re.compile(
    r"(?P<index>\d+)\s*\n"
    r"(?P<start>\d{2}:\d{2}:\d{2},\d{3})\s-->\s(?P<end>\d{2}:\d{2}:\d{2},\d{3})\s*\n"
    r"(?P<text>.*?)(?=\n{2,}|\Z)",
    re.DOTALL,
)


def create_logger(placeholder: st.delta_generator.DeltaGenerator) -> Callable[[str], None]:
    """åœ¨é¡µé¢åº•éƒ¨å®æ—¶è¾“å‡ºæ—¥å¿—ã€‚"""
    log_lines: List[str] = []
    placeholder.info("æ—¥å¿—å°†åœ¨ä»»åŠ¡å¼€å§‹åæ˜¾ç¤ºã€‚")

    def log(message: str) -> None:
        log_lines.append(message)
        placeholder.code("\n".join(log_lines), language="bash")

    return log


def parse_timestamp_to_seconds(timestamp: str) -> float:
    hours, minutes, rest = timestamp.split(":")
    seconds, millis = rest.split(",")
    total = (
        int(hours) * 3600
        + int(minutes) * 60
        + int(seconds)
        + int(millis) / 1000.0
    )
    return total


def parse_srt_segments(srt_text: str) -> List[Dict[str, object]]:
    segments: List[Dict[str, object]] = []
    for match in SRT_BLOCK_RE.finditer(srt_text.strip()):
        index = int(match.group("index"))
        start = match.group("start")
        end = match.group("end")
        text = match.group("text").strip()
        segments.append(
            {
                "index": index,
                "start": start,
                "end": end,
                "start_seconds": parse_timestamp_to_seconds(start),
                "end_seconds": parse_timestamp_to_seconds(end),
                "text": text,
            }
        )
    return segments


def chunk_sequence(items: Sequence[Dict[str, object]], chunk_size: int):
    for start in range(0, len(items), chunk_size):
        yield list(items[start : start + chunk_size])


def extract_json_array(text: str):
    cleaned = text.strip()
    if cleaned.startswith("```"):
        cleaned = re.sub(r"^```(?:json)?", "", cleaned).strip()
        cleaned = re.sub(r"```$", "", cleaned).strip()
    return json.loads(cleaned)


def translate_chunk_with_openai(
    client: OpenAI,
    model: str,
    target_language: str,
    chunk: Sequence[Dict[str, object]],
) -> Dict[int, str]:
    system_prompt = (
        "ä½ æ˜¯ä¸€åä¸“ä¸šå­—å¹•ç¿»è¯‘ã€‚"
        f"è¯·å°†è¾“å…¥çš„å­—å¹•å†…å®¹ç¿»è¯‘æˆ{target_language}ï¼Œä¿æŒåŸæ„å’Œè¯­æ°”ï¼Œä¸è¦ä¸¢å¤±æ•°å­—æˆ–ä¸“æœ‰åè¯ã€‚"
        "åªè¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« index (æ•°å­—) å’Œ translation (å­—ç¬¦ä¸²)ã€‚"
    )
    formatted_lines = []
    for seg in chunk:
        text = " ".join(str(seg["text"]).split())
        formatted_lines.append(f"{seg['index']}|{text}")
    user_prompt = (
        "ä»¥ä¸‹æ˜¯éœ€è¦ç¿»è¯‘çš„å­—å¹•è¡Œï¼Œæ ¼å¼ä¸º index|æ–‡æœ¬ ï¼š\n"
        + "\n".join(formatted_lines)
        + "\nè¯·ç¿»è¯‘ä¸ºç›®æ ‡è¯­è¨€ï¼Œåªè¿”å› JSON æ•°ç»„ã€‚"
    )

    response = client.chat.completions.create(
        model=model,
        temperature=0.2,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    )
    content = response.choices[0].message.content or ""
    data = extract_json_array(content)
    result: Dict[int, str] = {}
    for item in data:
        idx = int(item["index"])
        translation = str(item["translation"]).strip()
        result[idx] = translation
    return result


def main() -> None:
    st.set_page_config(
        page_title="è§†é¢‘å­—å¹•å·¥å…·ç®±",
        page_icon="ğŸ¬",
        layout="centered",
    )
    st.title("ğŸ¬ è§†é¢‘å­—å¹•å·¥å…·ç®±")
    tab_transcribe, tab_burn, tab_translate = st.tabs(
        ["ğŸ¯ è§†é¢‘è½¬å­—å¹•", "ğŸ”¥ å­—å¹•çƒ§å½•", "ğŸ§  AI å­—å¹•ç¿»è¯‘"]
    )

    with tab_transcribe:
        st.subheader("è§†é¢‘ / éŸ³é¢‘ â†’ SRT å­—å¹•")
        st.write(
            "ä¸Šä¼ è§†é¢‘æˆ–éŸ³é¢‘ï¼Œé€‰æ‹©è¯†åˆ«å‚æ•°åç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶ã€‚é»˜è®¤æ”¯æŒä¸­æ–‡ï¼ŒåŒæ—¶ä¹Ÿå¯è¯†åˆ«è‹±æ–‡ (en) å’Œæ—¥è¯­ (ja)ã€‚"
            "é¦–æ¬¡ä½¿ç”¨æŸä¸ªæ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½ã€‚"
        )

        upload = st.file_uploader(
            "ä¸Šä¼ è§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶",
            type=VIDEO_TYPES + AUDIO_TYPES,
            key="transcribe_upload",
        )
        if upload:
            st.caption(f"å·²é€‰æ‹©ï¼š{upload.name}ï¼ˆçº¦ {upload.size / (1024 * 1024):.2f} MBï¼‰")

        col_left, col_right = st.columns(2)
        with col_left:
            model_options = ["tiny", "base", "small", "medium", "large-v2", "large-v3"]
            model_choice = st.selectbox(
                "æ¨¡å‹å¤§å°/åç§°",
                model_options,
                index=1,
                key="model_choice",
                help="æ¨¡å‹è¶Šå¤§è¯†åˆ«è¶Šå‡†ã€è¶Šæ…¢ï¼›tiny/base æ›´å¿«ã€medium/large æ›´å‡†ç¡®ã€‚",
            )
            custom_model = st.text_input(
                "è‡ªå®šä¹‰æ¨¡å‹/æœ¬åœ°è·¯å¾„ï¼ˆå¯é€‰ï¼‰",
                key="custom_model",
                help="ç•™ç©ºä½¿ç”¨ä¸Šæ–¹åˆ—è¡¨ï¼Œä¹Ÿå¯ä»¥å¡«å†™æœ¬åœ°æ¨¡å‹ç›®å½•æˆ– HuggingFace ä»“åº“åã€‚",
            )
            language_choice = st.selectbox(
                "å¸¸ç”¨è¯­è¨€",
                [
                    ("è‡ªåŠ¨æ£€æµ‹", ""),
                    ("ä¸­æ–‡ (zh)", "zh"),
                    ("è‹±æ–‡ (en)", "en"),
                    ("æ—¥è¯­ (ja)", "ja"),
                ],
                format_func=lambda item: item[0],
                key="language_choice",
                help="é€‰æ‹©å¸¸ç”¨è¯­è¨€å¯å¿«é€Ÿè®¾ç½®ï¼Œä¹Ÿå¯ä»¥åœ¨ä¸‹æ–¹è‡ªå®šä¹‰å…¶å®ƒè¯­è¨€ä»£ç ã€‚",
            )
            language_custom = st.text_input(
                "è‡ªå®šä¹‰è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰",
                value="",
                key="lang_input",
                help="å¡«å†™ ISO 639-1 ä»£ç ï¼Œå¦‚ zh/en/jaã€‚å¦‚æœç•™ç©ºåˆ™ä½¿ç”¨ä¸Šæ–¹çš„å¸¸ç”¨è¯­è¨€æˆ–è‡ªåŠ¨æ£€æµ‹ã€‚",
            )
            language = language_custom.strip() or language_choice[1]
            model_size = custom_model.strip() or model_choice
        with col_right:
            device = st.selectbox(
                "æ¨ç†è®¾å¤‡",
                ["auto", "cpu", "cuda", "metal"],
                index=0,
                key="device_select",
                help="auto ä¼šè‡ªåŠ¨é€‰æ‹©å¯ç”¨ GPUï¼›å¦‚æœè¯†åˆ«å¤±è´¥ï¼Œå¯æ‰‹åŠ¨åˆ‡æ¢ä¸º cpuã€‚",
            )
            compute_type = st.selectbox(
                "è®¡ç®—ç²¾åº¦",
                ["int8_float16", "int8", "float16", "float32"],
                index=0,
                key="compute_select",
                help="int8/float16 æ›´èŠ‚çœæ˜¾å­˜ï¼Œfloat32 æœ€å…¼å®¹ã€‚å¦‚å‡ºé”™è¯·æ”¹ä¸º float32ã€‚",
            )
            vad_filter = st.checkbox(
                "å¯ç”¨ VAD ç«¯ç‚¹æ£€æµ‹",
                value=True,
                key="vad_checkbox",
                help="å¼€å¯åä¼šè‡ªåŠ¨å‰”é™¤é™éŸ³ç‰‡æ®µï¼Œå­—å¹•æ›´å¹²å‡€ã€‚è‹¥è¯†åˆ«ä¸åˆ°å£°éŸ³å¯å…³é—­ã€‚",
            )

        st.markdown("#### æ‰§è¡Œæ—¥å¿—")
        transcribe_log_placeholder = st.empty()

        if st.button("å¼€å§‹ç”Ÿæˆå­—å¹•", type="primary", key="start_transcribe"):
            if upload is None:
                st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ã€‚")
            else:
                log = create_logger(transcribe_log_placeholder)
                suffix = Path(upload.name).suffix or ".mp4"
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_video:
                    tmp_video.write(upload.getbuffer())
                    tmp_video_path = Path(tmp_video.name)
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_audio:
                    tmp_audio_path = Path(tmp_audio.name)

                try:
                    log("1) æå–éŸ³é¢‘ä¸­...")
                    extract_audio(tmp_video_path, tmp_audio_path)
                    log("2) å¼€å§‹è¯­éŸ³è¯†åˆ«...")
                    segments = list(
                        transcribe_audio(
                            tmp_audio_path,
                            model_size,
                            language,
                            device,
                            compute_type,
                            vad_filter,
                        )
                    )
                    log(f"å®Œæˆï¼å…±è¾“å‡º {len(segments)} æ¡å­—å¹•ã€‚")
                except Exception as exc:  # pragma: no cover - UIå¼‚å¸¸å±•ç¤º
                    log(f"å‡ºé”™ï¼š{exc}")
                    st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{exc}")
                    return
                finally:
                    tmp_video_path.unlink(missing_ok=True)
                    tmp_audio_path.unlink(missing_ok=True)

                srt_text = build_srt_content(segments)
                default_name = Path(upload.name).with_suffix(".srt").name

                st.success("å­—å¹•ç”Ÿæˆå®Œæˆ âœ…")
                st.download_button(
                    label="ä¸‹è½½ SRT å­—å¹•",
                    data=srt_text.encode("utf-8"),
                    file_name=default_name,
                    mime="application/x-subrip",
                )
                st.text_area("å­—å¹•é¢„è§ˆ", srt_text, height=320, key="srt_preview")

    with tab_burn:
        st.subheader("å­—å¹•çƒ§å½•ï¼ˆSRT â†’ è§†é¢‘ï¼‰")
        st.write(
            "å°†å·²æœ‰çš„ SRT å­—å¹•çƒ§å½•è¿›è§†é¢‘ç”»é¢ï¼Œé€‚åˆå‘å¸ƒéœ€è¦å†…åµŒå­—å¹•çš„å¹³å°ã€‚"
            "æ”¯æŒè°ƒæ•´å­—ä½“å¤§å°æˆ–é€šè¿‡ force_style è®¾ç½®æ›´å¤æ‚æ ·å¼ã€‚"
        )

        burn_video = st.file_uploader(
            "ä¸Šä¼ éœ€è¦çƒ§å½•å­—å¹•çš„è§†é¢‘",
            type=VIDEO_TYPES,
            key="burn_video_upload",
        )
        burn_srt = st.file_uploader(
            "ä¸Šä¼ å­—å¹•æ–‡ä»¶ï¼ˆSRTï¼‰",
            type=["srt"],
            key="burn_srt_upload",
        )

        col_font, col_style = st.columns(2)
        with col_font:
            font_size = st.slider(
                "å­—å¹•å­—ä½“å¤§å°",
                min_value=16,
                max_value=48,
                value=28,
                step=1,
                key="font_slider",
                help="ä»…å¯¹é»˜è®¤æ ·å¼ç”Ÿæ•ˆï¼Œå•ä½ä¸ºç‚¹ã€‚å¯é…åˆå³ä¾§ force_style ä½¿ç”¨ã€‚",
            )
        with col_style:
            custom_style = st.text_input(
                "force_style é«˜çº§å‚æ•°ï¼ˆå¯é€‰ï¼‰",
                help="ç•™ç©ºåˆ™ä»…æ§åˆ¶å­—ä½“å¤§å°ã€‚ç¤ºä¾‹ï¼šFontName=Arial,PrimaryColour=&HFFFFFF&",
                key="custom_force_style",
            )

        st.markdown("#### æ‰§è¡Œæ—¥å¿—")
        burn_log_placeholder = st.empty()

        if st.button("å¼€å§‹çƒ§å½•å­—å¹•", type="secondary", key="start_burn"):
            if burn_video is None or burn_srt is None:
                st.warning("è¯·åŒæ—¶ä¸Šä¼ è§†é¢‘å’Œ SRT å­—å¹•æ–‡ä»¶ã€‚")
            else:
                log = create_logger(burn_log_placeholder)
                video_suffix = Path(burn_video.name).suffix or ".mp4"
                with tempfile.NamedTemporaryFile(delete=False, suffix=video_suffix) as tmp_video:
                    tmp_video.write(burn_video.getbuffer())
                    tmp_video_path = Path(tmp_video.name)
                with tempfile.NamedTemporaryFile(delete=False, suffix=".srt") as tmp_srt:
                    tmp_srt.write(burn_srt.getbuffer())
                    tmp_srt_path = Path(tmp_srt.name)
                with tempfile.NamedTemporaryFile(delete=False, suffix=video_suffix) as tmp_output:
                    tmp_output_path = Path(tmp_output.name)

                force_style = (
                    custom_style.strip()
                    if custom_style.strip()
                    else f"Fontsize={font_size}"
                )

                try:
                    log("1) è°ƒç”¨ ffmpeg çƒ§å½•å­—å¹•...")
                    burn_subtitles(
                        tmp_video_path,
                        tmp_srt_path,
                        tmp_output_path,
                        force_style=force_style,
                    )
                    log("2) çƒ§å½•å®Œæˆï¼Œå‡†å¤‡æä¾›ä¸‹è½½ã€‚")
                    burned_bytes = tmp_output_path.read_bytes()
                except Exception as exc:  # pragma: no cover - UIå¼‚å¸¸å±•ç¤º
                    log(f"å‡ºé”™ï¼š{exc}")
                    st.error(f"çƒ§å½•å¤±è´¥ï¼š{exc}")
                    return
                finally:
                    tmp_video_path.unlink(missing_ok=True)
                    tmp_srt_path.unlink(missing_ok=True)
                    tmp_output_path.unlink(missing_ok=True)

                video_stem = Path(burn_video.name).stem
                output_name = f"{video_stem}_sub{video_suffix}"

                st.success("å­—å¹•çƒ§å½•å®Œæˆ âœ…")
                st.download_button(
                    label="ä¸‹è½½çƒ§å½•åçš„è§†é¢‘",
                    data=burned_bytes,
                    file_name=output_name,
                    mime="video/mp4",
                )

    with tab_translate:
        st.subheader("AI å­—å¹•ç¿»è¯‘ï¼ˆSRT â†’ SRTï¼‰")
        st.write(
            "ä¸Šä¼  SRT å­—å¹•æ–‡ä»¶ï¼Œç³»ç»Ÿä¼šæŒ‰å°æ®µæ‰¹é‡è°ƒç”¨ OpenAI æ¥å£ç¿»è¯‘ã€‚"
            "éœ€è¦å¡«å†™ API Base ä¸ API Keyï¼ˆå…¼å®¹ OpenAI ç»Ÿä¸€æ ¼å¼ï¼Œä¾‹å¦‚å®˜æ–¹/ç¬¬ä¸‰æ–¹å…¼å®¹æœåŠ¡ï¼‰ã€‚"
        )

        api_base = st.text_input(
            "API Base",
            value="https://api.openai.com/v1",
            help="OpenAI ç»Ÿä¸€æ ¼å¼çš„æ¥å£åœ°å€ï¼Œç»“å°¾é€šå¸¸ä¸º /v1ã€‚",
            key="translate_api_base",
        )
        api_key = st.text_input(
            "API Key",
            value="",
            type="password",
            help="ä¸ä¼šè¢«ä¿å­˜ï¼Œä»…åœ¨æœ¬æ¬¡ä¼šè¯å†…ä½¿ç”¨ã€‚",
            key="translate_api_key",
        )
        model_name = st.text_input(
            "æ¨¡å‹åç§°",
            value="gpt-4o-mini",
            help="è¯·è¾“å…¥å¯ç”¨çš„èŠå¤©/å¤šæ¨¡æ€æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ gpt-4o-miniã€gpt-4o-mini-translationã€‚",
            key="translate_model",
        )
        target_lang = st.selectbox(
            "ç›®æ ‡è¯­è¨€",
            ["ä¸­æ–‡", "è‹±æ–‡", "æ—¥è¯­", "éŸ©è¯­", "è¥¿ç­ç‰™è¯­"],
            help="ç¿»è¯‘å°†è¾“å‡ºè¯¥è¯­è¨€ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æè¿°ç»™æ¨¡å‹ã€‚",
            key="translate_target",
        )
        chunk_size = st.slider(
            "æ¯æ‰¹ç¿»è¯‘çš„å­—å¹•æ¡æ•°",
            min_value=3,
            max_value=20,
            value=6,
            help="ä¸€æ¬¡è¯·æ±‚å¤„ç†çš„å­—å¹•æ¡æ•°ã€‚æ•°å€¼è¶Šå¤§é€Ÿåº¦è¶Šå¿«ä½†å›ç­”è¶Šé•¿ï¼Œå»ºè®® 3-10ã€‚",
            key="translate_chunk_size",
        )

        translate_upload = st.file_uploader(
            "ä¸Šä¼ éœ€è¦ç¿»è¯‘çš„ SRT å­—å¹•",
            type=["srt"],
            key="translate_upload",
        )

        st.markdown("#### æ‰§è¡Œæ—¥å¿—")
        translate_log_placeholder = st.empty()

        if st.button("å¼€å§‹ç¿»è¯‘å­—å¹•", type="primary", key="start_translate"):
            if translate_upload is None:
                st.warning("è¯·å…ˆä¸Šä¼  SRT æ–‡ä»¶ã€‚")
                return
            if not api_base.strip() or not api_key.strip():
                st.warning("è¯·å¡«å†™ API Base ä¸ API Keyã€‚")
                return
            log = create_logger(translate_log_placeholder)
            try:
                srt_text = translate_upload.getvalue().decode("utf-8")
            except UnicodeDecodeError:
                st.error("æ–‡ä»¶ä¸æ˜¯ UTF-8 ç¼–ç ï¼Œè¯·è½¬æ¢åå†è¯•ã€‚")
                return

            segments = parse_srt_segments(srt_text)
            if not segments:
                st.warning("æœªè§£æåˆ°ä»»ä½•å­—å¹•æ®µï¼Œè¯·ç¡®è®¤ SRT æ ¼å¼ã€‚")
                return

            log(f"å·²è§£æ {len(segments)} æ¡å­—å¹•ï¼Œå¼€å§‹åˆ†æ‰¹ç¿»è¯‘...")
            client = OpenAI(api_key=api_key.strip(), base_url=api_base.strip())

            translated_map: Dict[int, str] = {}
            total_batches = (len(segments) + chunk_size - 1) // chunk_size

            for batch_idx, chunk in enumerate(chunk_sequence(segments, chunk_size), start=1):
                log(f"ç¬¬ {batch_idx}/{total_batches} æ‰¹ï¼šè°ƒç”¨æ¨¡å‹ç¿»è¯‘ {len(chunk)} æ¡å­—å¹•...")
                try:
                    chunk_result = translate_chunk_with_openai(
                        client=client,
                        model=model_name.strip(),
                        target_language=target_lang,
                        chunk=chunk,
                    )
                except Exception as exc:  # pragma: no cover - ç½‘ç»œå¼‚å¸¸å±•ç¤º
                    log(f"å‡ºé”™ï¼š{exc}")
                    st.error(f"ç¿»è¯‘å¤±è´¥ï¼š{exc}")
                    return
                translated_map.update(chunk_result)
                preview_lines = []
                for seg in chunk:
                    translated_text = chunk_result.get(seg["index"])
                    if translated_text:
                        original = " ".join(str(seg["text"]).splitlines())
                        preview_lines.append(
                            f'{seg["index"]}: "{original}" -> "{translated_text}"'
                        )
                if preview_lines:
                    log("ç»“æœé¢„è§ˆï¼š\n" + "\n".join(preview_lines))

            translated_segments = [
                (
                    seg["index"],
                    seg["start_seconds"],
                    seg["end_seconds"],
                    translated_map.get(seg["index"], seg["text"]),
                )
                for seg in segments
            ]
            translated_srt = build_srt_content(translated_segments)

            st.success("å­—å¹•ç¿»è¯‘å®Œæˆ âœ…")
            trans_stem = Path(translate_upload.name).stem
            translated_name = f"{trans_stem}_{target_lang}.srt"
            st.download_button(
                label="ä¸‹è½½ç¿»è¯‘åçš„ SRT",
                data=translated_srt.encode("utf-8"),
                file_name=translated_name,
                mime="application/x-subrip",
            )
            st.text_area("ç¿»è¯‘ç»“æœé¢„è§ˆ", translated_srt, height=300, key="translated_preview")


if __name__ == "__main__":
    main()
